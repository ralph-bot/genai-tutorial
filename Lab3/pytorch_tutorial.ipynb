{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Readme\n",
    "pytorch 主要课程安排：\n",
    "1. pytorch 的基本概念\n",
    "2. pytorch 的基本操作\n",
    "3. pytorch 的模型构建\n",
    "4. pytorch 的模型训练\n",
    "5. pytoch 实战 -- MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/fengrao/miniconda3/envs/py39/lib/python3.9/site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in /Users/fengrao/miniconda3/envs/py39/lib/python3.9/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/fengrao/miniconda3/envs/py39/lib/python3.9/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Users/fengrao/miniconda3/envs/py39/lib/python3.9/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/fengrao/miniconda3/envs/py39/lib/python3.9/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /Users/fengrao/miniconda3/envs/py39/lib/python3.9/site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/fengrao/miniconda3/envs/py39/lib/python3.9/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/fengrao/miniconda3/envs/py39/lib/python3.9/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/fengrao/miniconda3/envs/py39/lib/python3.9/site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一、前置知识：张量与计算图\n",
    "\n",
    "在 PyTorch 中，所有计算都基于张量（Tensor），而 backward() 的核心是「计算图」—— 一种记录张量运算的有向无环图（DAG），用于自动求导。\n",
    "\n",
    "1.1 张量的 requires_grad 属性\n",
    "requires_grad=True：标记该张量需要计算梯度（通常是模型参数，如权重 / 偏置）。\n",
    "requires_grad=False：默认值，无需计算梯度（通常是输入数据、标签）。\n",
    "运算生成的张量会继承梯度属性（除非手动关闭）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z = tensor([6.], grad_fn=<MulBackward0>)\n",
      "z.requires_grad: True\n",
      "z.grad_fn: <MulBackward0 object at 0x313bafaf0>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "# 1. 基础张量与梯度标记\n",
    "x = torch.tensor([2.0], requires_grad=True)  # 需计算梯度的张量（模拟模型参数）\n",
    "y = torch.tensor([3.0])  # 无需计算梯度（模拟输入）\n",
    "\n",
    "# 2. 简单运算：z = x * y\n",
    "z = x * y\n",
    "print(\"z =\", z)  # tensor([6.], grad_fn=<MulBackward0>)\n",
    "print(\"z.requires_grad:\", z.requires_grad)  # True（继承x的梯度属性）\n",
    "print(\"z.grad_fn:\", z.grad_fn)  # 记录运算类型（乘法反向传播函数）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 计算图的本质\n",
    "\n",
    "y (叶子节点，无梯度)\n",
    "  \\\n",
    "   * (运算节点，grad_fn=MulBackward0)\n",
    "  /\n",
    "x (叶子节点，需梯度)\n",
    "   \\\n",
    "    z (结果节点)\n",
    "\n",
    "叶子节点（leaf node）：直接创建的张量（如 x、y），非运算生成。\n",
    "非叶子节点：运算生成的张量（如 z），梯度计算后会被清空（节省内存）。\n",
    "grad_fn：记录生成该张量的运算，用于反向传播时计算梯度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "二、损失函数（Loss）：模型优化的目标    \n",
    "损失函数（Loss Function）是衡量「模型预测值」与「真实标签」差距的指标，优化的核心是最小化损失。\n",
    "\n",
    "损失函数的本质: 损失函数本质是一个「以模型参数为自变量的函数」，通过反向传播可计算损失对每个参数的梯度（即参数的更新方向）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测值 y_pred: tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.,\n",
      "        15., 16., 17., 18., 19., 20.], grad_fn=<AddBackward0>)\n",
      "损失值 loss: tensor(165.5000, grad_fn=<MseLossBackward0>)\n",
      "损失值 loss_2: tensor(11.5000, grad_fn=<MeanBackward0>)\n",
      "损失值 loss_3: tensor(3051.8171, grad_fn=<DivBackward1>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 模拟线性回归：y = 2x + 1（真实参数 w=2, b=1）\n",
    "x_data = torch.tensor([1.0, 2.0, 3.0])  # 输入\n",
    "y_true = torch.tensor([3.0, 5.0, 7.0])  # 真实标签（2*1+1=3，2*2+1=5...）\n",
    "\n",
    "# 模型参数（需计算梯度）\n",
    "w = torch.tensor([1.0], requires_grad=True)  # 初始值1（目标是优化到2）\n",
    "b = torch.tensor([0.0], requires_grad=True)  # 初始值0（目标是优化到1）\n",
    "\n",
    "# 1. 前向传播：计算预测值\n",
    "y_pred = w * x_data + b\n",
    "print(\"预测值 y_pred:\", y_pred)  # tensor([1., 2., 3.], grad_fn=<AddBackward0>)\n",
    "\n",
    "# 2. 计算损失（MSELoss）\n",
    "loss_fn = torch.nn.MSELoss()  # 实例化均方误差损失\n",
    "loss = loss_fn(y_pred, y_true)\n",
    "print(\"损失值 loss:\", loss)  # tensor(4.6667)（(1-3)²+(2-5)²+(3-7)² /3 = (4+9+16)/3=29/3≈9.6667？哦，我算错了：(1-3)²=4，(2-5)²=9，(3-7)²=16 → 总和29 → 29/3≈9.6667，代码输出是9.6667）\n",
    "\n",
    "\n",
    "loss_fn_2 = torch.nn.L1Loss()\n",
    "loss_2 = loss_fn_2(y_pred, y_true)\n",
    "print(\"损失值 loss_2:\", loss_2)  # tensor(2.6667)（(1-3)²+(2-5)²+(3-7)² /3 = (4+9+16)/3=29/3≈9.6667？哦，我算错了：(1-3)²=4，(2-5)²=9，(3-7)²=16 → 总和29 → 29/3≈9.6667，代码输出是9.6667）\n",
    "\n",
    "loss_fn_3 = torch.nn.CrossEntropyLoss()\n",
    "loss_3 = loss_fn_3(y_pred, y_true)\n",
    "print(\"损失值 loss_3:\", loss_3)  # tensor(2.6667)（(1-3)²+(2-5)²+(3-7)² /3 = (4+9+16)/3=29/3≈9.6667？哦，我算错了：(1-3)²=4，(2-5)²=9，(3-7)²=16 → 总和29 → 29/3≈9.6667，代码输出是9.6667）\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "三、反向传播（backward）：计算梯度\n",
    "backward() 是 PyTorch 自动求导的核心方法，作用是从损失节点出发，沿计算图反向遍历，计算所有 requires_grad=True 的张量的梯度（存储在张量的 .grad 属性中）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#插入图像\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# 插入本地图片（假设图片名为 'backward_graph.png'，位于当前目录）\n",
    "display(Image(filename='backward_graph.png'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调用 backward 计算梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w的梯度 dw: tensor([-308.])\n",
      "b的梯度 db: tensor([-23.])\n",
      "y_pred.grad: None\n",
      "loss.grad: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7s/p20wf5f921z0gb6kl59f60gw0000gn/T/ipykernel_95546/4048109901.py:17: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/core/TensorBody.h:494.)\n",
      "  print(\"y_pred.grad:\", y_pred.grad)  # None（非叶子节点，梯度不保留）\n",
      "/var/folders/7s/p20wf5f921z0gb6kl59f60gw0000gn/T/ipykernel_95546/4048109901.py:18: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/core/TensorBody.h:494.)\n",
      "  print(\"loss.grad:\", loss.grad)      # None（损失是标量，无需梯度）\n"
     ]
    }
   ],
   "source": [
    "# 接上面的代码：计算loss后调用backward\n",
    "# 模拟线性回归：y = 2x + 1（真实参数 w=2, b=1）\n",
    "#x_data = torch.tensor([1.0, 2.0, 3.0])  # 输入\n",
    "#y_true = torch.tensor([3.0, 5.0, 7.0])  # 真实标签（2*1+1=3，2*2+1=5...）\n",
    "\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "# 查看梯度（存储在 .grad 属性中）\n",
    "print(\"w的梯度 dw:\", w.grad)  \n",
    "# y_pred = [1,2,3], y_true=[3,5,7] → 误差=[-2,-3,-4]\n",
    "# dw = 2/3 * (-2*1 + -3*2 + -4*3) = 2/3*(-2-6-12) = 2/3*(-20) = -40/3 ≈-13.3333\n",
    "# db = 2/3 * (-2 + -3 + -4) = 2/3*(-9) = -6\n",
    "print(\"b的梯度 db:\", b.grad)  # tensor([-6.])\n",
    "\n",
    "# 验证：非叶子节点的梯度会被清空（默认行为）\n",
    "print(\"y_pred.grad:\", y_pred.grad)  # None（非叶子节点，梯度不保留）\n",
    "print(\"loss.grad:\", loss.grad)      # None（损失是标量，无需梯度）\n",
    "\n",
    "#关键说明：\n",
    "#梯度累加问题：.grad 属性会累加多次 backward() 的结果，因此每次迭代前需要手动清零（如 w.grad.zero_()）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "梯度清零：避免累加\n",
    "如果多次调用 backward()，梯度会累加，导致参数更新错误。因此在迭代训练中，每次反向传播后需清零梯度："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "清零后w的梯度: tensor([1.9646e-05])\n"
     ]
    }
   ],
   "source": [
    "# 模拟第二次反向传播（先清零）\n",
    "w.grad.zero_()  # 清零w的梯度\n",
    "b.grad.zero_()  # 清零b的梯度\n",
    "\n",
    "# 重新计算损失并反向传播\n",
    "y_pred_new = w * x_data + b\n",
    "loss_new = loss_fn(y_pred_new, y_true)\n",
    "loss_new.backward()\n",
    "\n",
    "print(\"清零后w的梯度:\", w.grad)  # 重新计算的梯度，无累加"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 完整训练流程 ：损失→反向传播→参数更新\n",
    "结合优化器（如 SGD），完整的「前向传播→计算损失→反向传播→参数更新」流程如下：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Loss: 0.0640, w: 2.1248, b: 0.5275\n",
      "Epoch 100, Loss: 0.0250, w: 2.1790, b: 0.5821\n",
      "Epoch 150, Loss: 0.0221, w: 2.1721, b: 0.6081\n",
      "Epoch 200, Loss: 0.0196, w: 2.1623, b: 0.6310\n",
      "Epoch 250, Loss: 0.0174, w: 2.1528, b: 0.6526\n",
      "Epoch 300, Loss: 0.0154, w: 2.1439, b: 0.6729\n",
      "Epoch 350, Loss: 0.0136, w: 2.1355, b: 0.6919\n",
      "Epoch 400, Loss: 0.0121, w: 2.1276, b: 0.7099\n",
      "Epoch 450, Loss: 0.0107, w: 2.1202, b: 0.7269\n",
      "Epoch 500, Loss: 0.0095, w: 2.1131, b: 0.7428\n",
      "Epoch 550, Loss: 0.0084, w: 2.1065, b: 0.7578\n",
      "Epoch 600, Loss: 0.0075, w: 2.1003, b: 0.7719\n",
      "Epoch 650, Loss: 0.0066, w: 2.0945, b: 0.7853\n",
      "Epoch 700, Loss: 0.0059, w: 2.0890, b: 0.7978\n",
      "Epoch 750, Loss: 0.0052, w: 2.0838, b: 0.8096\n",
      "Epoch 800, Loss: 0.0046, w: 2.0789, b: 0.8207\n",
      "Epoch 850, Loss: 0.0041, w: 2.0743, b: 0.8312\n",
      "Epoch 900, Loss: 0.0036, w: 2.0699, b: 0.8410\n",
      "Epoch 950, Loss: 0.0032, w: 2.0659, b: 0.8503\n",
      "Epoch 1000, Loss: 0.0029, w: 2.0620, b: 0.8590\n",
      "Epoch 1050, Loss: 0.0025, w: 2.0584, b: 0.8673\n",
      "Epoch 1100, Loss: 0.0022, w: 2.0550, b: 0.8750\n",
      "Epoch 1150, Loss: 0.0020, w: 2.0518, b: 0.8823\n",
      "Epoch 1200, Loss: 0.0018, w: 2.0488, b: 0.8892\n",
      "Epoch 1250, Loss: 0.0016, w: 2.0459, b: 0.8956\n",
      "Epoch 1300, Loss: 0.0014, w: 2.0432, b: 0.9017\n",
      "Epoch 1350, Loss: 0.0012, w: 2.0407, b: 0.9075\n",
      "Epoch 1400, Loss: 0.0011, w: 2.0383, b: 0.9129\n",
      "Epoch 1450, Loss: 0.0010, w: 2.0361, b: 0.9180\n",
      "Epoch 1500, Loss: 0.0009, w: 2.0340, b: 0.9227\n",
      "Epoch 1550, Loss: 0.0008, w: 2.0320, b: 0.9272\n",
      "Epoch 1600, Loss: 0.0007, w: 2.0301, b: 0.9315\n",
      "Epoch 1650, Loss: 0.0006, w: 2.0284, b: 0.9355\n",
      "Epoch 1700, Loss: 0.0005, w: 2.0267, b: 0.9393\n",
      "Epoch 1750, Loss: 0.0005, w: 2.0252, b: 0.9428\n",
      "Epoch 1800, Loss: 0.0004, w: 2.0237, b: 0.9461\n",
      "Epoch 1850, Loss: 0.0004, w: 2.0223, b: 0.9493\n",
      "Epoch 1900, Loss: 0.0003, w: 2.0210, b: 0.9522\n",
      "Epoch 1950, Loss: 0.0003, w: 2.0198, b: 0.9550\n",
      "Epoch 2000, Loss: 0.0003, w: 2.0186, b: 0.9577\n",
      "Epoch 2050, Loss: 0.0002, w: 2.0175, b: 0.9601\n",
      "Epoch 2100, Loss: 0.0002, w: 2.0165, b: 0.9625\n",
      "Epoch 2150, Loss: 0.0002, w: 2.0156, b: 0.9646\n",
      "Epoch 2200, Loss: 0.0002, w: 2.0146, b: 0.9667\n",
      "Epoch 2250, Loss: 0.0001, w: 2.0138, b: 0.9687\n",
      "Epoch 2300, Loss: 0.0001, w: 2.0130, b: 0.9705\n",
      "Epoch 2350, Loss: 0.0001, w: 2.0122, b: 0.9722\n",
      "Epoch 2400, Loss: 0.0001, w: 2.0115, b: 0.9738\n",
      "Epoch 2450, Loss: 0.0001, w: 2.0108, b: 0.9754\n",
      "Epoch 2500, Loss: 0.0001, w: 2.0102, b: 0.9768\n",
      "Epoch 2550, Loss: 0.0001, w: 2.0096, b: 0.9781\n",
      "Epoch 2600, Loss: 0.0001, w: 2.0091, b: 0.9794\n",
      "Epoch 2650, Loss: 0.0001, w: 2.0085, b: 0.9806\n",
      "Epoch 2700, Loss: 0.0000, w: 2.0080, b: 0.9818\n",
      "Epoch 2750, Loss: 0.0000, w: 2.0076, b: 0.9828\n",
      "Epoch 2800, Loss: 0.0000, w: 2.0071, b: 0.9838\n",
      "Epoch 2850, Loss: 0.0000, w: 2.0067, b: 0.9848\n",
      "Epoch 2900, Loss: 0.0000, w: 2.0063, b: 0.9857\n",
      "Epoch 2950, Loss: 0.0000, w: 2.0059, b: 0.9865\n",
      "Epoch 3000, Loss: 0.0000, w: 2.0056, b: 0.9873\n",
      "Epoch 3050, Loss: 0.0000, w: 2.0053, b: 0.9880\n",
      "Epoch 3100, Loss: 0.0000, w: 2.0050, b: 0.9887\n",
      "Epoch 3150, Loss: 0.0000, w: 2.0047, b: 0.9894\n",
      "Epoch 3200, Loss: 0.0000, w: 2.0044, b: 0.9900\n",
      "Epoch 3250, Loss: 0.0000, w: 2.0041, b: 0.9906\n",
      "Epoch 3300, Loss: 0.0000, w: 2.0039, b: 0.9911\n",
      "Epoch 3350, Loss: 0.0000, w: 2.0037, b: 0.9916\n",
      "Epoch 3400, Loss: 0.0000, w: 2.0035, b: 0.9921\n",
      "Epoch 3450, Loss: 0.0000, w: 2.0033, b: 0.9926\n",
      "Epoch 3500, Loss: 0.0000, w: 2.0031, b: 0.9930\n",
      "Epoch 3550, Loss: 0.0000, w: 2.0029, b: 0.9934\n",
      "Epoch 3600, Loss: 0.0000, w: 2.0027, b: 0.9938\n",
      "Epoch 3650, Loss: 0.0000, w: 2.0026, b: 0.9942\n",
      "Epoch 3700, Loss: 0.0000, w: 2.0024, b: 0.9945\n",
      "Epoch 3750, Loss: 0.0000, w: 2.0023, b: 0.9948\n",
      "Epoch 3800, Loss: 0.0000, w: 2.0021, b: 0.9951\n",
      "Epoch 3850, Loss: 0.0000, w: 2.0020, b: 0.9954\n",
      "Epoch 3900, Loss: 0.0000, w: 2.0019, b: 0.9957\n",
      "Epoch 3950, Loss: 0.0000, w: 2.0018, b: 0.9959\n",
      "Epoch 4000, Loss: 0.0000, w: 2.0017, b: 0.9962\n",
      "Epoch 4050, Loss: 0.0000, w: 2.0016, b: 0.9964\n",
      "Epoch 4100, Loss: 0.0000, w: 2.0015, b: 0.9966\n",
      "Epoch 4150, Loss: 0.0000, w: 2.0014, b: 0.9968\n",
      "Epoch 4200, Loss: 0.0000, w: 2.0013, b: 0.9970\n",
      "Epoch 4250, Loss: 0.0000, w: 2.0012, b: 0.9972\n",
      "Epoch 4300, Loss: 0.0000, w: 2.0012, b: 0.9973\n",
      "Epoch 4350, Loss: 0.0000, w: 2.0011, b: 0.9975\n",
      "Epoch 4400, Loss: 0.0000, w: 2.0010, b: 0.9976\n",
      "Epoch 4450, Loss: 0.0000, w: 2.0010, b: 0.9978\n",
      "Epoch 4500, Loss: 0.0000, w: 2.0009, b: 0.9979\n",
      "Epoch 4550, Loss: 0.0000, w: 2.0009, b: 0.9980\n",
      "Epoch 4600, Loss: 0.0000, w: 2.0008, b: 0.9981\n",
      "Epoch 4650, Loss: 0.0000, w: 2.0008, b: 0.9982\n",
      "Epoch 4700, Loss: 0.0000, w: 2.0007, b: 0.9983\n",
      "Epoch 4750, Loss: 0.0000, w: 2.0007, b: 0.9984\n",
      "Epoch 4800, Loss: 0.0000, w: 2.0006, b: 0.9985\n",
      "Epoch 4850, Loss: 0.0000, w: 2.0006, b: 0.9986\n",
      "Epoch 4900, Loss: 0.0000, w: 2.0006, b: 0.9987\n",
      "Epoch 4950, Loss: 0.0000, w: 2.0005, b: 0.9988\n",
      "Epoch 5000, Loss: 0.0000, w: 2.0005, b: 0.9988\n",
      "\n",
      "训练完成：\n",
      "优化后的w: 2.0005（目标2）\n",
      "优化后的b: 0.9988（目标1）\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 1. 数据准备\n",
    "x_data = torch.tensor([1.0, 2.0, 3.0])\n",
    "y_true = torch.tensor([3.0, 5.0, 7.0])  # y=2x+1\n",
    "\n",
    "# x_data = torch.tensor([1.0, 2.0, 3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0,20.0])  # 输入\n",
    "# y_true = torch.tensor([3.0, 5.0, 7.0, 9.0, 11.0, 13.0, 15.0, 17.0, 19.0, 21.0, 23.0, 25.0, 27.0, 29.0, 31.0, 33.0, 35.0, 37.0, 39.0, 41.0])  # 真实标签（2*1+1=3，2*2+1=5...）\n",
    "\n",
    "# 2. 模型参数（需梯度）\n",
    "w = torch.tensor([1.0], requires_grad=True)\n",
    "b = torch.tensor([0.0], requires_grad=True)\n",
    "\n",
    "# 3. 定义损失函数和优化器\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.SGD([w, b], lr=0.005)  # 随机梯度下降，学习率0.01\n",
    "# 4. 迭代训练（500轮）\n",
    "epochs = 500\n",
    "for epoch in range(epochs):\n",
    "    # 前向传播\n",
    "    y_pred = w * x_data + b\n",
    "    \n",
    "    # 计算损失\n",
    "    loss = loss_fn(y_pred, y_true)\n",
    "    \n",
    "    # 梯度清零（关键！否则梯度累加）\n",
    "    optimizer.zero_grad()  # 等价于 w.grad.zero_() + b.grad.zero_()\n",
    "    \n",
    "    # 反向传播：计算梯度\n",
    "    loss.backward()\n",
    "    \n",
    "    # 参数更新（优化器自动用梯度更新参数）\n",
    "    optimizer.step()  # 等价于 w.data = w.data -  lr * w.grad; b.data -= lr * b.grad\n",
    "    \n",
    "    # 每50轮打印一次\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}, w: {w.item():.4f}, b: {b.item():.4f}\")\n",
    "\n",
    "# 最终结果（接近真实值w=2, b=1）\n",
    "print(\"\\n训练完成：\")\n",
    "print(f\"优化后的w: {w.item():.4f}（目标2）\")\n",
    "print(f\"优化后的b: {b.item():.4f}（目标1）\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x (1797, 64)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxsAAAGBCAYAAAAOvKzFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAiRklEQVR4nO3dDXBcVf0/4FMIAgo2BRQEsaECIiMSLAKi2FRAEdFGBcQ3GkVlFLRlfKE6aosvWFRsfEGoL5Ci+EIRU0UHpdow6igCkioqgrQR8QVBkiCjoIX7m3P/k/7bNFDK2ZPdu/s8M0vKds/Zs5tv9+7n3nPPnVIURREAAABqbKtadwgAABAJGwAAQBbCBgAAkIWwAQAAZCFsAAAAWQgbAABAFsIGAACQhbABAABkIWwAAABZtHzYGBoaClOmTAmf/OQna9bnwMBA2Wf8CQ9H/VFP6o96U4PUk/qbHJUMG319feUv8rrrrgvN6i9/+Us48cQTQ3t7e3j84x8f5syZE9asWVPvYdEC9feHP/whnHHGGeHwww8P2223Xfla4wcyjaHZ6+/yyy8Pr3rVq8KMGTPCYx/72PC0pz0tvPOd7wwjIyP1HhotUoPf/va3w4te9KKw++67h2233TY8+clPDscff3y48cYb6z00WqD+xjv66KPL13v66aeHqmqr9wDY1L333htmz54dRkdHw/ve976wzTbbhCVLloRZs2aFwcHBsPPOO9d7iDSxn//85+Ezn/lM2H///cPTn/70suZgsrzlLW8pv+S97nWvC095ylPCb37zm/C5z30ufP/73w+/+tWvwvbbb1/vIdLkYs1NmzYtzJs3L+yyyy7h73//e7jwwgvDIYccUn4+HnjggfUeIi3i8ssvL2uu6oSNBvT5z38+3HLLLeGXv/xlePazn13e9+IXvzg84xnPCOeee244++yz6z1EmtjLXvayci/yjjvuWB5aFjaYTJdddlno6ura6L6ZM2eGuXPnhksuuSS86U1vqtvYaA0f/OAHN7kv1l08wnH++eeHCy64oC7jorXcd9995VHdM888c8KarJJKTqN6JP773/+Wv5y4kZo6dWp43OMeF4444oiwatWqh2wTjx5Mnz693HMWjyJMdMj0pptuKg+n7rTTTuUUk4MPPjh85zvf2ex4/v3vf5dt77rrrke0sY0hYyxoRPvtt1848sgjw6WXXrrZ9tRflesv9h2DBtVV5fobHzSil7/85eXP3//+95ttT2Oocg1O5IlPfGI5rc90vmpohvr7+Mc/Hh588MHwrne9K1Rd04aNe+65J3zpS18qN1znnHNOWLRoUbjzzjvLeZgT7am9+OKLy6kjp512Wnjve99bFtkLXvCCcMcdd6x/zG9/+9tw2GGHlRu8BQsWlEcZYgF3d3eXczwfTjxKEaekxOkADycW1q9//euygMeLh3BvvfXW8K9//WuL3gsmX1Xrj+bQbPUXp7FEcUoL1dAMNRiDRRxznFYVj2zE1xR3+tH4ql5/t912W1i8eHE59qaYOlpU0EUXXVTEoV977bUP+Zh169YV999//0b3DQ8PF7vuumvxxje+cf19a9euLfvafvvti9tvv339/ddcc015/xlnnLH+viOPPLI44IADivvuu2/9fQ8++GBx+OGHF/vss8/6+1atWlW2jT/H37dw4cKHfW133nln+bgPfehDm/zdeeedV/7dTTfd9LB9kFcz1994n/jEJ8p2cZw0hlaqvzGnnHJKsfXWWxc333zzo2pPbbVKDT7taU8r28TbDjvsULz//e8vHnjggUfcnjxaof6OP/74st8xse1pp51WVFXTHtnYeuutw2Me85j1RwvuvvvusG7duvKIQTzJcLyYTPfYY4+NjiIceuih5UmJUWz/4x//uFwhKh5ZiIfC4u2f//xnmZTjORZxBamHEtN1rJeYrh/Of/7zn/JnXAFjvHjIbsPH0LiqWn80h2aqv6997Wvhy1/+cjl3eZ999tni9tRHM9TgRRddFK688sryPMq4Vzpuex944IEtfCeohyrX36pVq8K3vvWt0NvbG5pFU58gvmzZsvIwV5wn97///W/9/Xvttdcmj51oI7bvvvuuP0fij3/8Y1koH/jAB8rbRP7xj39sVKyPxtjhsvvvv3/Ck4U2fAyNrYr1R/Nohvr7yU9+Ek455ZRyY/7Rj360pn2TX9Vr8DnPec76P5900kll4IhqeU0G8qli/a1bty684x3vCK9//es3Om+36po2bHz1q18NPT09ZVp997vfXZ7cFZPuxz72sfK8hy0Vk3EUT9SJG76J7L333snjjicdxaMaf/vb3zb5u7H74rKQNLaq1h/NoRnqb/Xq1eXKaHEVvrhoRltb026umlIz1OCG4lK4cQ5/XBFN2Gh8Va2/iy++uLzW1dKlSze5vlU8ohLvG1usoEqa9tM7bpziRaHiGsXxYihjFi5cOOHj4yGw8W6++ebQ0dFR/jn2FcVrXhx11FHZxr3VVluFAw44YMKL1VxzzTXlOKwU1PiqWn80h6rXX/wycMwxx5Qb1TiNYYcddsj+nNRW1WtwInEaVbz+FY2vqvV32223lUdhnvvc504YROItnoweQ1SVNPU5G9H/O6/m/39Zf6iLo/T392803y6uHBAfH69vEcWNXpxzF9PmREcd4ioHtVr2LC6rdu21124UOGLSjfMFTzjhhM22p/6qXH9UX5XrL6489cIXvrDc8fKDH/wgPOEJT9hsGxpPlWswTocZL+5R/tGPfjThSpE0nqrW30knnVSGifG36Nhjjy3/HM8lqZpKH9mIV/SMJ2+NF6/6edxxx5WJNq7P/pKXvCSsXbu2vBBPvCpyvEL3RIe/nve854W3vvWt5fkS8cSceKXu97znPesfc95555WPiUce3vzmN5dJNy6LFov39ttvLw/7P5RYuPGq4DFVb+4Eobe97W3hi1/8YjnueMguJulPfepTYddddy1PkqQxNGv9xT13n/3sZ8s//+xnPyt/xuX62tvby9vpp5++Re8TeTRr/cUjGmvWrCmf+6c//Wl5GxM/A48++ugteJfIqVlrMPYfl7jt7Owsp0/Fvd5xkYK4xzkuR0pjaMb622+//crbROK5JlU7orFeUeFlzx7q9uc//7lcjuzss88upk+fXmy77bbFQQcdVFxxxRXF3Llzy/vGL3sWl/g899xziz333LN8/BFHHFGsXr16k+e+9dZbi5NPPrnYbbfdim222abYY489iuOOO6647LLLarrsWXwNcemzxz/+8eWSe/E5brnlluT3jnTNXn9jY5rotuHYqY9mr7+He22zZs2qyXtImmavwfiYgw8+uJg2bVrR1tZW7L777sVJJ51U/PrXv67J+0eaZq+/iVR96dsp8T/1DjwAAEDzadpzNgAAgPoSNgAAgCyEDQAAIAthAwAAyELYAAAAshA2AACA+l7Ub8PLvddLLa6eXYsL8qxcuTK5jwULFiS1Hx4eDo1gslZOboT6q4WBgYHkPuKF9VLFCwulWLFiRWgEk7lyd7PUYLwKbqp4td1Ug4ODdX8dtdBKn4FnnnlmQ2yD40UfU6VeCdw2uJpqsf3s6+tL7qO7qhfne5T158gGAACQhbABAABkIWwAAABZCBsAAEAWwgYAAJCFsAEAAGQhbAAAAFkIGwAAQBbCBgAAkIWwAQAAZCFsAAAAWQgbAABAFsIGAACQhbABAABkIWwAAABZCBsAAEAWbaFCFi9enNzHjBkzkvuYNm1ach933313UvsTTzwxeQzLly9P7oMtMzIyktzHrFmzkvuYPXt2UvsVK1Ykj4Et19nZmdzHqlWrkvsYHR1N7qOjoyO5DyZ3G3rCCSckj+HUU09N7mPp0qXJfcycOTOp/cqVK5PHwOTr6elJ7mNwcLAmY2kljmwAAABZCBsAAEAWwgYAAJCFsAEAAGQhbAAAAFkIGwAAQBbCBgAAkIWwAQAAZCFsAAAAWQgbAABAFsIGAACQhbABAABkIWwAAABZCBsAAEAWwgYAAJBFW5hEM2fOTGo/Y8aM5DE89alPTe5jzZo1yX1cddVVdX0vo+XLlyf30Uo6OzuT++jq6gqNYHBwsN5D4FHo7u5O7mP16tXJffT39yf3sXDhwuQ+2DJf+MIXktqfc845yWO47rrrGmIbvHLlyuQ+mFzt7e3JffT09CT30dvbm9xHR0dHqLehoaFJey5HNgAAgCyEDQAAIAthAwAAyELYAAAAshA2AACALIQNAAAgC2EDAADIQtgAAACyEDYAAIAshA0AACALYQMAAMhC2AAAALIQNgAAgCyEDQAAIAthAwAAyELYAAAAsmgLk2jatGlJ7a+//vrkMaxZsyY0glq8FrbM/Pnzk9ovWrQoeQxTp04NjWBgYKDeQ+BR6O3tTe5jaGioIcaxYsWK5D6Y3O3fjBkzksdQiz5WrlxZ9+8jw8PDyWNgy/T09CT30dHRkdxHX19f3T9DR0ZGksdQi+80j5QjGwAAQBbCBgAAkIWwAQAAZCFsAAAAWQgbAABAFsIGAACQhbABAABkIWwAAABZCBsAAEAWwgYAAJCFsAEAAGQhbAAAAFkIGwAAQBbCBgAAkIWwAQAAZCFsAAAAWbSFSTRt2rSk9itXrgzNIvW9GB4ertlYWkVvb29S+76+vuQxNMrvrb29vd5DaEmp7/v8+fOTx9Dd3R0aQU9PT72HwBZas2ZNch877bRTch9XXXVV3fs4+uijm2Z7MFnmzJmT1H7JkiXJY1i2bFloBPPmzUtq/4Y3vCFUiSMbAABAFsIGAACQhbABAABkIWwAAABZCBsAAEAWwgYAAJCFsAEAAGQhbAAAAFkIGwAAQBbCBgAAkIWwAQAAZCFsAAAAWQgbAABAFsIGAACQhbABAABkIWwAAABZtIVJNDw8nNR+5syZoRFMmzYtuY/U17J8+fLkMdC6Ojs7k9oPDg7WbCytZNGiRUnt582bFxpBd3d3ch8jIyM1GQvVkvo9IDr66KOT+1i6dGlS+zPPPDN5DAsWLAitZHR0tK7to7lz59Z9+1kL/f39oUoc2QAAALIQNgAAgCyEDQAAIAthAwAAyELYAAAAshA2AACALIQNAAAgC2EDAADIQtgAAACyEDYAAIAshA0AACALYQMAAMhC2AAAALIQNgAAgCyEDQAAIIu2MInWrFmT1H7mzJnJYzjhhBMaoo9U55xzTr2HAGyhvr6+pPZdXV3JYzjwwAOT++jv70/uY8WKFUntL7roorqPodUsXrw4uY+VK1cm9zFt2rTkPo466qik9suXL08eQ6sZGBhIat/e3p48hs7Ozrq/jmjZsmUhxcjISKgSRzYAAIAshA0AACALYQMAAMhC2AAAALIQNgAAgCyEDQAAIAthAwAAyELYAAAAshA2AACALIQNAAAgC2EDAADIQtgAAACyEDYAAIAshA0AACALYQMAAMhC2AAAALJoC5NozZo1Se0XLFiQPIbFixcn93H99dcn93HwwQcn98HkGhkZSe5jxYoVyX3MmTMnuY+urq6k9n19fcljaEWDg4NJ7Ts7O5PHUIs+Fi1aVPc6Hhoaaoh/j61keHg4uY+lS5eGRrB8+fKk9qeeemrNxkK1tuNTp05N7qOvxbahjmwAAABZCBsAAEAWwgYAAJCFsAEAAGQhbAAAAFkIGwAAQBbCBgAAkIWwAQAAZCFsAAAAWQgbAABAFsIGAACQhbABAABkIWwAAABZCBsAAEAWwgYAAJCFsAEAAGQxpSiKIk/XAABAK3NkAwAAyELYAAAAshA2AACALIQNAAAgC2EDAADIQtgAAACyEDYAAIAshA0AACALYQMAAMhC2AAAALIQNgAAgCyEDQAAIAthAwAAyELYAAAAshA2AACALIQNAAAgC2EDAADIQtgAAACyEDYAAIAshA0AACALYQMAAMhC2AAAALIQNgAAgCyEDQAAIAthAwAAyELYAAAAshA2AACALIQNAAAgC2EDAADIQtgAAACyEDYAAIAshA0AACALYQMAAMhC2AAAALIQNgAAgCyEDQAAIAthAwAAyELYAAAAshA2AACALIQNAAAgC2EDAADIQtgAAACyEDYAAIAshA0AACALYQMAAMhC2AAAALIQNgAAgCyEDQAAIAthAwAAyELYAAAAshA2AACALIQNAAAgC2EDAADIQtgAAACyaPmwMTQ0FKZMmRI++clP1qzPgYGBss/4Ex6O+qOe1B/1pgapJ/U3OSoZNvr6+spf5HXXXRea0aJFi8rXN/623Xbb1XtotED9jfnmN78ZnvOc54THPe5xob29PRx++OHhxz/+cb2H1fKavf46Ojom/PyLt3322afew6MFajBauXJlmD17dthll13Kz79DDjkkfOUrX6n3sGiR+vvGN74RnvWsZ5Xf+57whCeEU045Jdx1112hqtrqPQAe2vnnnx922GGH9f+/9dZb13U8tI4YeD/0oQ+F448/PvT09IT//e9/4cYbbwx/+ctf6j00mlxvb2+49957N7rvT3/6U3j/+98fXvjCF9ZtXLSO73znO6G7u7vc2TK28+/SSy8NJ598cvmF74wzzqj3EGny735ve9vbwpFHHhk+9alPhdtvvz18+tOfLsPVNddcU8kdz8JGA4tf9OJeFZhMv/jFL8qgce6559qoMunil7zxPvKRj5Q/X/va19ZhRLSaz33uc+FJT3pSeSR32223Le879dRTw3777VfuVfe5SC7//e9/w/ve977w/Oc/P1x11VVl0I3izIKXvvSl4Ytf/GJ4+9vfHqqmktOoHukv7IMf/GCYOXNmmDp1ajkV5IgjjgirVq16yDZLliwJ06dPD9tvv32YNWtWuSd3vJtuuqkMATvttFOZLg8++OByL8jm/Pvf/y7bbslhsKIowj333FP+pFqqXH9xz/Juu+0W5s2bV9be+L3MNL4q199Evva1r4W99tqr3OBSDVWuwbjdnTZt2vqgEbW1tZU7/+LYaHxVrb8bb7wxjIyMhFe96lXrg0Z03HHHlTNd4vSqKmrasBE/LL70pS+Frq6ucM4555SHQu+8887wohe9KAwODm7y+Isvvjh85jOfCaeddlp473vfW/7CX/CCF4Q77rhj/WN++9vfhsMOOyz8/ve/DwsWLCj3/MYCjnvivv3tbz/seH75y1+Gpz/96eUek0dqxowZ5T+SHXfcMbzuda/baCw0tirX349+9KPw7Gc/uxxPnCsa6y/u5duS2qW+qlx/491www3lc77mNa/Z4rbUT5VrMI45PtcHPvCB8Mc//jHceuut4cMf/nA5jeU973nPo3xHmExVrb/777+//DlRqI33xc/DBx98MFROUUEXXXRR3NVfXHvttQ/5mHXr1hX333//RvcNDw8Xu+66a/HGN75x/X1r164t+9p+++2L22+/ff3911xzTXn/GWecsf6+I488sjjggAOK++67b/19Dz74YHH44YcX++yzz/r7Vq1aVbaNP8fft3Dhws2+vt7e3uL0008vLrnkkuKyyy4r5s2bV7S1tZXPMTo6utn25NXM9Xf33XeXj9t5552LHXbYofjEJz5RfPOb3yyOOeaY8v4LLrjgEb1H5NPM9TeRd77znWXb3/3ud1vcljyavQbvvffe4sQTTyymTJlStom3xz72sUV/f/9m25JfM9ffnXfeWdbdKaecstH9N9100/pavOuuu4qqadojG/Fk6sc85jHln2MKvPvuu8O6devKQ16/+tWvNnl8TKZ77LHH+v+PK08ceuih4fvf/375/7F9nL954oknhn/961/lobB4++c//1km5VtuueVhT56N6TpOSYnpenPi9JXPfvaz5Z68V77yleW0lmXLlpXP8fnPf/5RviNMpqrW39iUqdhv3Cv0rne9q3zO733ve2H//fdfP3eexlbV+hsvjj1OGzjooIPKvYJUR5VrME6f2nfffcvpMl//+tfDV7/61XLccYZBPKeNxlfV+ttll13K54jf+eKRkzVr1oSf/OQn5bSqbbbZpnzMf/7zn1A1TRs2ovjLeuYzn1nOq9t5553LKSHxS9Po6Ogmj51oScX4YRPXYI7iodRYKPGwauxnw9vChQvLx/zjH//I9lpi8Ijz6ONyfFRDFetv7NBt/FCLG9oxW221VflhF1fFuO2225Kfh/yqWH/jXX311eUG3Inh1VTVGjz99NPDd7/73TLonnTSSWX9xW1vnE4adwZSDVWtv6VLl4Zjjz223Nn31Kc+tTxZ/IADDihPEI82XKW0Kpp2Naq4JyIu2RnT6rvf/e7wxCc+sUy6H/vYx8r5l1tqbI5c/OXHFDuRvffeO+S05557lumaxlfV+hs76S2uKz9+qeX4GqLh4eHwlKc8Jfm5yKeq9TfeJZdcUgbdV7/61TXvm7yqWoPxxOIvf/nL5bkZsfbGxB0wL37xi8s59/ExY3vNaUxVrb8onqu7YsWKcsdeDDvxpPV4iwtkxHATt89V07Rh47LLLitPsL788ss3OqN/LIGOFw+BjXfzzTeXF5iKYl9jHzhHHXVUmGwxUceii9MJaHxVrb+4ce3s7AzXXnvtJhvUv/71r+XP+GFHY6tq/Y0/UfJb3/pWOf1g9913n5TnpHaqWoNxWkycbvPAAw9s8nfxekPxS+dEf0djqWr9bSju1BvbsRdXqLr++uvLqfVV1LTTqMb2ym64bGy8GMrPf/7zCR/f39+/0Xy7uHJAfHzckxHFVBw3evHw1t/+9rdN2sdVDmq17N5EfcWLvMT7jznmmM22p/6qXH9xulTcmMZD0GPuu+++ci9zPG/DF7/GV+X6GxPnSscNrClU1VTVGozPE/ccx9WF4g6XDc9ni1Or4rU2LH/b+Kpafw8lrpAVQ3BVr/FS6SMbF154Ybjyyis3uT/OqYxrEsdE+/KXvzy85CUvCWvXrg0XXHBB+WVpousGxMNfz3ve88Jb3/rWco9aPCk7zvHbcJm78847r3xMnDv35je/uUy6cVm0WLxxLvvq1asfcqyxcGfPnl2m6s2dIBQPl8UvfPF54pSWn/70p+Xc0bjHOV5YiMbQrPUXayyeHB6XAIx7duKela985SvlVZzjxpbG0Kz1NyaG23iiblX35LWCZqzB+CU1TpWJV6yPy5zGq4bHnS9xalV8jjg9h8bQjPUXLV68uFx6N56gHq/vEoPQD3/4w3KBlrgsfSUVFV727KFuf/7zn8vlyM4+++xi+vTpxbbbblscdNBBxRVXXFHMnTu3vG/8smdxic9zzz232HPPPcvHH3HEEcXq1as3ee5bb721OPnkk4vddtut2GabbYo99tijOO6448olamu17N6b3vSmYv/99y923HHH8jn23nvv4swzzyzuueeemrx/pGn2+ovuuOOOcqw77bRTOZ5DDz20uPLKK5PfO9K1Qv3FJb6322674hWveEXy+0XttUINxqXnDznkkKK9vb1cFjV+Bm74HNRPs9ffFVdcUdZe/A4Yl1w+7LDDiksvvbSosinxP/UOPAAAQPNp2nM2AACA+hI2AACALIQNAAAgC2EDAADIQtgAAACyEDYAAID6XtRvw8u918vAwEByH0NDQ8l99PT0JPfRLCZr5eRGqL9GqeF4ddtU8QKRzWAyV+5uhBqcP39+Q9RPd3d3ch8HHnhgUvvR0dHkMXR0dCT3MTw8HFql/uKFzhqhdvr6+ur+WuLV7RtBK22D48XtGuHzL15JnC2rP0c2AACALIQNAAAgC2EDAADIQtgAAACyEDYAAIAshA0AACALYQMAAMhC2AAAALIQNgAAgCyEDQAAIAthAwAAyELYAAAAshA2AACALIQNAAAgC2EDAADIQtgAAACymFIURfGIHjhlSqi3oaGh5D6mT58eGsGf/vSnpPYdHR2hETzC8knWCPU3Z86c5D76+/uT+zjrrLOS+1i0aFFoBpNVf41Sg/Pnzw+NYHBwsO6vpb29PXkMXV1dyX200mfgwMBAch+Nsu1K/T5Ri9qphSrVX+rvfu3ataFZrF69Oql9Z2dnqFL9ObIBAABkIWwAAABZCBsAAEAWwgYAAJCFsAEAAGQhbAAAAFkIGwAAQBbCBgAAkIWwAQAAZCFsAAAAWQgbAABAFsIGAACQhbABAABkIWwAAABZCBsAAEAWbaFCRkZGkvuYPn16ch+jo6PJfQwMDCS1b29vb4j3s5WcddZZoRH09/fXewjUSW9vb2gEixYtSu6jo6MjqX1XV1fyGNgyg4ODyX0MDQ0l99HT01P37V8t6i/1e0DV1OJ7S6qrr766IWq4q8U+vxzZAAAAshA2AACALIQNAAAgC2EDAADIQtgAAACyEDYAAIAshA0AACALYQMAAMhC2AAAALIQNgAAgCyEDQAAIAthAwAAyELYAAAAshA2AACALIQNAAAgC2EDAADIoi1UyNDQUHIfBx54YHIfU6dOTe5jcHAwqf3IyEjyGNgy7e3tyX2sXr267rVD/XR1ddW1fa3Mnz+/3kMI3d3dyX309fXVZCytohbv1w033JDcR0dHR3IfqdvQWnwfaTWN8J7V4nOjv7+/Ib5PVIkjGwAAQBbCBgAAkIWwAQAAZCFsAAAAWQgbAABAFsIGAACQhbABAABkIWwAAABZCBsAAEAWwgYAAJCFsAEAAGQhbAAAAFkIGwAAQBbCBgAAkIWwAQAAZCFsAAAAWbSFCunu7k7uo6urK7mPzs7O5D6WLFkS6q23t7feQ6iU9vb25D6GhoaS+5g/f35yH/39/XV/Ha0o9X2rxWdPLT4DG+HzfGBgoGZjYfI+A2th1qxZyX3stddeSe19Bm65kZGRpParV69OHsPw8HByH5/+9KeT++hM/Czv6OhIHsNk1rAjGwAAQBbCBgAAkIWwAQAAZCFsAAAAWQgbAABAFsIGAACQhbABAABkIWwAAABZCBsAAEAWwgYAAJCFsAEAAGQhbAAAAFkIGwAAQBbCBgAAkIWwAQAAZCFsAAAAWbSFFjMwMBCaQUdHR72H0HKGhoaS+5g1a1ZyH+3t7cl9LFmyJKn9QQcdlDyGwcHB0GpSa6i7uzt5DEVRJPdRi3E0y2dxlXR2dia1X7VqVfIYzjrrrIbY/vX399f930AttimtJLV+a9VHI2y7ent7k/uoRQ0/Uo5sAAAAWQgbAABAFsIGAACQhbABAABkIWwAAABZCBsAAEAWwgYAAJCFsAEAAGQhbAAAAFkIGwAAQBbCBgAAkIWwAQAAZCFsAAAAWQgbAABAFsIGAACQRVuokDlz5iT3MTo6mtzHokWLQr319/fXewgtp6+vL7mPJUuWJPcxNDSU3EdHR0dS++7u7uQxDA4OJvfRanp7exviM/Dqq69O7oPJl/rZUYvaqUUNp35+RTfccENS+56enqb4LtFqarHdqUUN9yTWTy22wZPJkQ0AACALYQMAAMhC2AAAALIQNgAAgCyEDQAAIAthAwAAyELYAAAAshA2AACALIQNAAAgC2EDAADIQtgAAACyEDYAAIAshA0AACALYQMAAMhC2AAAALIQNgAAgCzaQoXMnj07uY958+aFRrBs2bKk9gMDAzUbC49MX19fch8dHR3JffT09CT3kVo//f39yWNgy3V1dSX3MXfu3OQ+RkZGkvtg8qX+3mqx3RkeHk7uY3R0NLmPFStWJLXv7e1NHgOT/553dnYm99He3l73z/LBwcFQJY5sAAAAWQgbAABAFsIGAACQhbABAABkIWwAAABZCBsAAEAWwgYAAJCFsAEAAGQhbAAAAFkIGwAAQBbCBgAAkIWwAQAAZCFsAAAAWQgbAABAFsIGAACQhbABAABkMaUoiiJP1wAAQCtzZAMAAMhC2AAAALIQNgAAgCyEDQAAIAthAwAAyELYAAAAshA2AACALIQNAAAgC2EDAAAIOfwf7vcK5S9h5zQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier  # 多层感知机分类器\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 加载手写数字数据集（1797张8x8像素的数字图片）\n",
    "digits = load_digits()\n",
    "X = digits.data  # 特征：64维向量（每张图片8x8像素）\n",
    "labels = digits.target  # 标签：0-9的数字\n",
    "\n",
    "print(\"x\" , X.shape)\n",
    "# 可视化前10张图片\n",
    "fig, axes = plt.subplots(2, 5, figsize=(10, 5))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(digits.images[i], cmap='gray')\n",
    "    ax.set_title(f\"Label: {labels[i]}\")\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n",
      "16.0\n",
      "torch.Size([1617, 1, 8, 8]) torch.Size([1617]) torch.Size([180, 1, 8, 8]) torch.Size([180])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "# 数据预处理：重塑为图像格式并归一化\n",
    "print(X.shape)\n",
    "print(X.max())  # 打印X的最大值\n",
    "\n",
    "X = X.reshape(-1, 1, 8, 8)  # 重塑为 (样本数, 通道数, 高度, 宽度)\n",
    "X = X / X.max() # 将像素值归一化到 [0,1] 范围\n",
    "\n",
    "feature_train, feature_validate, target_train, target_validate = train_test_split(X, labels, test_size = 0.1, random_state = 0)\n",
    "\n",
    "# 转换为PyTorch张量\n",
    "X_train = torch.FloatTensor(feature_train)\n",
    "y_train = torch.LongTensor(target_train)\n",
    "X_test = torch.FloatTensor(feature_validate)\n",
    "y_test = torch.LongTensor(target_validate)\n",
    "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataset.TensorDataset object at 0x313a310a0>\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# 创建数据加载器\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000)\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# 定义CNN模型（适应8x8图像）\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=3)  # 输入通道1，输出通道10\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=3)  # 输入通道10，输出通道20\n",
    "        self.conv2_drop = nn.Dropout2d()  # 卷积层的Dropout\n",
    "        self.fc1 = nn.Linear(20 * 1 * 1, 50)  # 全连接层\n",
    "        self.fc2 = nn.Linear(50, 10)  # 输出层\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)  # 卷积操作 (8-3+1=6) -> 6x6\n",
    "        x = nn.functional.max_pool2d(x, 2)  # 最大池化 -> 3x3\n",
    "        x = nn.functional.relu(x)  # ReLU激活函数\n",
    "        \n",
    "        x = self.conv2(x)  # 第二次卷积 (3-3+1=1) -> 1x1\n",
    "        x = self.conv2_drop(x)  # Dropout防止过拟合\n",
    "        x = nn.functional.max_pool2d(x, 1)  # 池化 (保持1x1)\n",
    "        x = nn.functional.relu(x)  # ReLU激活函数\n",
    "        \n",
    "        x = x.view(-1, 20 * 1 * 1)  # 展平为一维向量\n",
    "        x = self.fc1(x)  # 全连接层\n",
    "        x = nn.functional.relu(x)  # ReLU激活函数\n",
    "        x = nn.functional.dropout(x, training=self.training)  # Dropout\n",
    "        x = self.fc2(x)  # 输出层\n",
    "        return nn.functional.log_softmax(x, dim=1)  # 对数Softmax激活函数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cpu\n"
     ]
    }
   ],
   "source": [
    "# 初始化模型、损失函数和优化器\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"使用设备: {device}\")\n",
    "model = CNN().to(device)\n",
    "criterion = nn.NLLLoss()  # 负对数似然损失\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK开始训练CNN模型...\n",
      "Epoch 1/10, 损失: 2.3054, 耗时: 0.13秒\n",
      "Epoch 2/10, 损失: 2.2876, 耗时: 0.06秒\n",
      "Epoch 3/10, 损失: 2.2630, 耗时: 0.05秒\n",
      "Epoch 4/10, 损失: 2.2028, 耗时: 0.04秒\n",
      "Epoch 5/10, 损失: 2.0912, 耗时: 0.04秒\n",
      "Epoch 6/10, 损失: 1.9563, 耗时: 0.05秒\n",
      "Epoch 7/10, 损失: 1.8083, 耗时: 0.05秒\n",
      "Epoch 8/10, 损失: 1.6948, 耗时: 0.05秒\n",
      "Epoch 9/10, 损失: 1.6121, 耗时: 0.05秒\n",
      "Epoch 10/10, 损失: 1.5408, 耗时: 0.05秒\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# 训练模型\n",
    "def train(epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f'Epoch {epoch+1}/{epochs}, 损失: {running_loss/len(train_loader):.4f}, 耗时: {end_time-start_time:.2f}秒')\n",
    "# 训练和评估\n",
    "print(\"OK开始训练CNN模型...\")\n",
    "train(epochs=10)  # 由于数据集较小，增加训练轮次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "开始评估模型...\n",
      "测试集: 平均损失: 1.1604, 准确率: 137/180 (76.11%)\n"
     ]
    }
   ],
   "source": [
    "# 评估模型\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # 获取最大概率的索引\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    print(f'测试集: 平均损失: {test_loss:.4f}, 准确率: {correct}/{len(test_loader.dataset)} ({accuracy:.2f}%)')\n",
    "print(\"\\n开始评估模型...\")\n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
