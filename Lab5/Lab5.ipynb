{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "课程\n",
    "1. CNN MNIST\n",
    "2. 训练过程可视化\n",
    "3. 模型的存储和可视化\n",
    "4. RNN 代码课堂作业\n",
    "5. Attention 代码实现(Optional )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorboard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# 设置设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"使用设备: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载sklearn中的手写数字数据集\n",
    "digits = load_digits()\n",
    "X = digits.data  # 特征数据 (1797, 64)\n",
    "y = digits.target  # 标签数据 (1797,)\n",
    "\n",
    "# 数据预处理：重塑为图像格式并归一化\n",
    "X = X.reshape(-1, 1, 8, 8)  # 重塑为 (样本数, 通道数, 高度, 宽度)\n",
    "X = X / 16.0  # 将像素值归一化到 [0,1] 范围\n",
    "\n",
    "# 分割数据集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 转换为PyTorch张量\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "y_test = torch.LongTensor(y_test)\n",
    "\n",
    "# 创建数据加载器\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN 的核心概念是循环，它通过在时间维度上对输入序列进行迭代来捕捉序列中的长期依赖关系。\n",
    "对于图像信息， RNN 的应该循环什么？ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义CNN模型（适应8x8图像）\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=3)  # 输入通道1，输出通道10\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=3)  # 输入通道10，输出通道20\n",
    "        self.conv2_drop = nn.Dropout2d()  # 卷积层的Dropout\n",
    "        self.fc1 = nn.Linear(20 * 1 * 1, 50)  # 全连接层\n",
    "        self.fc2 = nn.Linear(50, 10)  # 输出层\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)  # 卷积操作 (8-3+1=6) -> 6x6\n",
    "        x = nn.functional.max_pool2d(x, 2)  # 最大池化 -> 3x3\n",
    "        x = nn.functional.relu(x)  # ReLU激活函数\n",
    "        \n",
    "        x = self.conv2(x)  # 第二次卷积 (3-3+1=1) -> 1x1\n",
    "        x = self.conv2_drop(x)  # Dropout防止过拟合\n",
    "        x = nn.functional.max_pool2d(x, 1)  # 池化 (保持1x1)\n",
    "        x = nn.functional.relu(x)  # ReLU激活函数\n",
    "        \n",
    "        x = x.view(-1, 20 * 1 * 1)  # 展平为一维向量\n",
    "        x = self.fc1(x)  # 全连接层\n",
    "        x = nn.functional.relu(x)  # ReLU激活函数\n",
    "        x = nn.functional.dropout(x, training=self.training)  # Dropout\n",
    "        x = self.fc2(x)  # 输出层\n",
    "        return nn.functional.log_softmax(x, dim=1)  # 对数Softmax激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化模型、损失函数和优化器\n",
    "# 定义RNN模型\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size=8, hidden_size=128, num_layers=2, num_classes=10):\n",
    "        pass\n",
    "        \n",
    "    def forward(self, x):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化RNN模型\n",
    "model = CNN().to(device)\n",
    "# criterion = nn.NLLLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "#model = CNN().to(device)\n",
    "criterion = nn.NLLLoss()  # 负对数似然损失\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "#criterion = CustomLoss(lambda_1=2.0, lambda_9=-0.5)  # 调整权重参数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            #print(data.shape) # [64,1,8,8]\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f'Epoch {epoch+1}/{epochs}, 损失: {running_loss/len(train_loader):.4f}, 耗时: {end_time-start_time:.2f}秒')\n",
    "\n",
    "# 评估模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # 获取最大概率的索引\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    print(f'测试集: 平均损失: {test_loss:.4f}, 准确率: {correct}/{len(test_loader.dataset)} ({accuracy:.2f}%)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练CNN模型...\n",
      "Epoch 1/20, 损失: 2.3023, 耗时: 0.25秒\n",
      "Epoch 2/20, 损失: 2.2899, 耗时: 0.13秒\n",
      "Epoch 3/20, 损失: 2.2550, 耗时: 0.13秒\n",
      "Epoch 4/20, 损失: 2.1995, 耗时: 0.13秒\n",
      "Epoch 5/20, 损失: 2.1011, 耗时: 0.13秒\n",
      "Epoch 6/20, 损失: 1.9537, 耗时: 0.13秒\n",
      "Epoch 7/20, 损失: 1.8108, 耗时: 0.12秒\n",
      "Epoch 8/20, 损失: 1.6962, 耗时: 0.12秒\n",
      "Epoch 9/20, 损失: 1.6287, 耗时: 0.13秒\n",
      "Epoch 10/20, 损失: 1.5551, 耗时: 0.13秒\n",
      "Epoch 11/20, 损失: 1.4406, 耗时: 0.13秒\n",
      "Epoch 12/20, 损失: 1.4353, 耗时: 0.13秒\n",
      "Epoch 13/20, 损失: 1.3782, 耗时: 0.13秒\n",
      "Epoch 14/20, 损失: 1.2884, 耗时: 0.13秒\n",
      "Epoch 15/20, 损失: 1.3061, 耗时: 0.14秒\n",
      "Epoch 16/20, 损失: 1.2825, 耗时: 0.13秒\n",
      "Epoch 17/20, 损失: 1.2583, 耗时: 0.13秒\n",
      "Epoch 18/20, 损失: 1.2339, 耗时: 0.13秒\n",
      "Epoch 19/20, 损失: 1.1933, 耗时: 0.14秒\n",
      "Epoch 20/20, 损失: 1.1893, 耗时: 0.14秒\n",
      "\n",
      "开始评估模型...\n",
      "测试集: 平均损失: 0.6740, 准确率: 300/360 (83.33%)\n"
     ]
    }
   ],
   "source": [
    "# 训练和评估\n",
    "print(\"开始训练CNN模型...\")\n",
    "train(epochs=20)  # 由于数据集较小，增加训练轮次\n",
    "print(\"\\n开始评估模型...\")\n",
    "test()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型训练过程中可视化\n",
    "Tensorboard  & wandB\n",
    "wandb 需要个人注册， 本次课堂就不展开了， 有兴趣的同学可以自己去了解。\n",
    "\n",
    "TensorBoard 是由 Google 开发的深度学习可视化工具，是 TensorFlow 生态系统的重要组成部分。它能将训练过程中的数据（如损失值、准确率、网络结构等）以直观的图表、图形形式呈现，帮助开发者理解模型训练动态、调试问题并优化模型。\n",
    "\n",
    "主要功能 （https://www.tensorflow.org/tensorboard?hl=zh-cn）\n",
    "跟踪和可视化损失及准确率等指标\n",
    "可视化模型图（操作和层）\n",
    "查看权重、偏差或其他张量随时间变化的直方图\n",
    "将嵌入投射到较低的维度空间\n",
    "显示图片、文字和音频数据 \n",
    "\n",
    "https://www.tensorflow.org/tensorboard/get_started?hl=zh-cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# 创建SummaryWriter对象，指定日志保存目录​\n",
    "writer = SummaryWriter('./my_experiment')\n",
    "def train(epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # 计算准确率\n",
    "            _, predicted = output.max(1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "        \n",
    "        end_time = time.time()\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        accuracy = 100. * correct / total\n",
    "        \n",
    "        # 记录训练损失和准确率到TensorBoard\n",
    "        writer.add_scalar('Training Loss', avg_loss, epoch)\n",
    "        writer.add_scalar('Training Accuracy', accuracy, epoch)\n",
    "        # writer.add_scalars(\n",
    "        # 'Loss Comparison',  # 图表标题\n",
    "        # {\n",
    "        #     'Train': avg_loss,\n",
    "        #     'Test': accuracy\n",
    "        # },\n",
    "        # epoch\n",
    "        # )   \n",
    "\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs}, 损失: {avg_loss:.4f}, 准确率: {accuracy:.2f}%, 耗时: {end_time-start_time:.2f}秒')\n",
    "# 评估模型\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练CNN模型...\n",
      "Epoch 1/20, 损失: 1.1662, 准确率: 56.58%, 耗时: 0.22秒\n",
      "Epoch 2/20, 损失: 1.1116, 准确率: 58.11%, 耗时: 0.15秒\n",
      "Epoch 3/20, 损失: 1.1313, 准确率: 59.50%, 耗时: 0.13秒\n",
      "Epoch 4/20, 损失: 1.1299, 准确率: 58.66%, 耗时: 0.14秒\n",
      "Epoch 5/20, 损失: 1.0866, 准确率: 60.54%, 耗时: 0.14秒\n",
      "Epoch 6/20, 损失: 1.0741, 准确率: 61.52%, 耗时: 0.13秒\n",
      "Epoch 7/20, 损失: 1.0169, 准确率: 62.91%, 耗时: 0.13秒\n",
      "Epoch 8/20, 损失: 1.0083, 准确率: 62.56%, 耗时: 0.13秒\n",
      "Epoch 9/20, 损失: 1.0287, 准确率: 62.49%, 耗时: 0.13秒\n",
      "Epoch 10/20, 损失: 1.0112, 准确率: 64.16%, 耗时: 0.13秒\n",
      "Epoch 11/20, 损失: 0.9769, 准确率: 65.48%, 耗时: 0.13秒\n",
      "Epoch 12/20, 损失: 0.9608, 准确率: 65.97%, 耗时: 0.13秒\n",
      "Epoch 13/20, 损失: 0.9814, 准确率: 64.02%, 耗时: 0.13秒\n",
      "Epoch 14/20, 损失: 0.9657, 准确率: 66.04%, 耗时: 0.13秒\n",
      "Epoch 15/20, 损失: 0.9621, 准确率: 65.48%, 耗时: 0.13秒\n",
      "Epoch 16/20, 损失: 0.9175, 准确率: 66.46%, 耗时: 0.13秒\n",
      "Epoch 17/20, 损失: 0.9229, 准确率: 65.83%, 耗时: 0.13秒\n",
      "Epoch 18/20, 损失: 0.9255, 准确率: 66.25%, 耗时: 0.13秒\n",
      "Epoch 19/20, 损失: 0.8892, 准确率: 66.32%, 耗时: 0.16秒\n",
      "Epoch 20/20, 损失: 0.8884, 准确率: 68.48%, 耗时: 0.13秒\n",
      "\n",
      "开始评估模型...\n",
      "测试集: 平均损失: 0.3668, 准确率: 332/360 (92.22%)\n"
     ]
    }
   ],
   "source": [
    "print(\"开始训练CNN模型...\")\n",
    "train(epochs=20)  # 由于数据集较小，增加训练轮次\n",
    "print(\"\\n开始评估模型...\")\n",
    "test()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.19.0 at http://localhost:6008/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=./my_experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "课堂练习： \n",
    "1. Tensorboard 对比不同学习率的结果\n",
    "2. 将 test 的结果拿进来做分析\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TASK: 模型存储 & 可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only save the weight \n",
    "torch.save(model, 'model.pth')\n",
    "# 保存参数\n",
    "torch.save(model.state_dict(), 'model_weights.pth')\n",
    "# we visualzie it in https://netron.app/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TASK : 定制 LOSS， 假设我希望提升 label = 1 的准确率， 降低 label = 9 的准确率， 应该怎么实现？ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self, lambda_1=1.5, lambda_9=-0.5):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        pass\n",
    "        \n",
    "\n",
    "        \n",
    "    def forward(self, outputs, targets):\n",
    "        pass\n",
    "        \n",
    "\n",
    "criterion = CustomLoss(lambda_1=2.0, lambda_9=0.01)  # 调整权重参数\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "akshare",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
